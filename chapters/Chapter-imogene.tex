\section*{Introduction du chapitre \thechapter}

Dans le chapitre \ref{ch:maxent}, nous avons vu comment décrire l'interaction
TF-ADN lorsque des sites de fixation sont connus. Dans ce chapitre, nous
adoptons une démarche plus générale. Nous connaissons l'activité de régulation
d'un certain nombre de CRMs, et nous souhaitons savoir quels TFs s'y fixent
(recherche de motifs), et si le génome contient d'autres CRMs avec la même
activité (recherche de modules). Un algorithme permettant précisément de
réaliser ces étapes a été développé précédemment par Hervé Rouault et appliqué
au cas de la différenciation des organes sensoriels de la
Drosophile~\cite{Rouault2010p327}. Nous présentons ici l'extension de cet
algorithme au cas des mammifères, ainsi que son utilisation comme outil de
classification de CRMs associés à différentes régulations.


\section{Recherche de motifs dans des CRMs} 
\label{sec:recherche_de_motifs_dans_des_crms}

Avant de rentrer dans le détail d'Imogene, nous présentons les méthodes
existantes de recherche de motifs dans des CRMs. Le problème général est le
suivant : étant données des CRMs conduisant à une même régulation, peut-on
construire des modèles de sites de fixation qui \og expliquent \fg cette
co-régulation, \cad qui prédisent l'existence de sites sur les CRMs mais
pas sur des séquences ne participant pas à la corégulation? L'une des
difficultés majeures ici est que la position des sites dans les séquences n'est
pas connue.

\subsection{Apprentissage par espérance-maximisation}
\label{sub:algorithmes_de_type_esp_rance_maximisation}

L'une des premières approches de ce problème a été celle de
MEME~\cite{Bailey1994fk}, un algorithme basé sur la méthode
d'espérance-maximisation ou EM (\textit{expectation maximization}) utilisée
précédemment dans ce cadre par \citet{Lawrence1990uq}. Cet algorithme se base
sur une approche générative pour décrire les processus probabilistes qui ont
permis la génération des séquences CRMs (fig.~\ref{fig:d_haeseleer-MEME}). 

\bfig
\includegraphics[width=0.8\textwidth]{figures/d_haeseleer-MEME.pdf}
\captionbf{Illustration de l'approche espérance-maximisation}{

Figure tirée de \cite{Dhaeseleer2006kx} décrivant l'approche EM. Un premier
modèle de motif est construit à partir d'un site initial. Ce modèle permet de
pondérer l'ensemble de sites sur les séquences (étape E). En rouge sont montrés
les meilleurs sites pour chaque séquence. En utilisant ces poids, il est
possible de construire un modèle de vraisemblance maximale (étape M). La
méthode originale de \citet{Lawrence1990uq} fait l'hypothèse qu'il
y a exactement un site de fixation par séquence, condition qui est relâchée par
MEME. 

} \label{fig:d_haeseleer-MEME} \efig


\subsubsection{Vraisemblance d'une séquence}
\label{ssub:vraisemblance_d_une_s_quence}


Notons $S=\{S_1,\cdots,S_L\}$ une séquence de taille $L$\footnote{On concatène
les deux brins d'ADN dans cette séquence. On suppose en effet qu'ils
participent équiprobablement à la fixation. Ainsi la séquence génomique double
brins est de longueur $L/2$.}. Supposons qu'il y a exactement un site de
régulation par CRM. C'est l'approche de \citet{Lawrence1990uq}, et cette
condition est relâchée par MEME, qui autorise l'utilisateur à préciser un
nombre moyen de sites par séquence. La probabilité que la séquence possède un
site de taille $K$ à la position $i$ étant donné le modèle $\mathcal{M}$
s'écrit 

\begin{equation}
    \label{eq:prob-sequence-oops}
    P(S|i,\mathcal{M}) = P_0(S_{1,i-1})\times P(S_{i,i+K-1} | \mathcal{M})\times P_0(S_{K,L})
\end{equation}

où $S_{i,j}$ dénote la séquence entre les positions $i$ et $j$ incluses,
$P(S_{i,i+K-1}|\mathcal{M})$ est la probabilité de générer la séquence de
taille $K$ débutant à la position $i$ avec le modèle $\mathcal{M}$ (voir
section \ref{sec:mod_les_pour_d_crire_les_corr_lations}), et $P_0(s)$ est la
probabilité neutre ou \textit{background} de générer la séquence $s$. Cette
dernière est généralement prise comme étant une chaîne de Markov
$\mathcal{P}_k$ d'ordre $k$ petit ($0$ ou $1$) :

\begin{equation}
    P_0(S_{i,j}) = \prod_{l=i}^{j} \mathcal{P}_k(S_l | S_{l-k,l-1})
\end{equation}

Ainsi, l'équation \ref{eq:prob-sequence-oops} décrit la probabilité de générer
la séquence $S$ avec le modèle \textit{background}, sauf à la position $i$ où
un site est généré avec le modèle de fixation $\mathcal{M}$. La probabilité de générer la séquence s'obtient finalement en sommant sur les positions pondérées par la probabilité \apriori $P(i)$ que le site soit à la position $i$ :

\begin{equation}
    P(S|\mathcal{M}) = \sum_{i=1}^{L-K+1} P(i) P(S|i,\mathcal{M})
\end{equation}

Cette probabilité est généralement prise uniforme, mais on peut y incorporer
certaines informations \apriori, comme le nombre de \textit{reads} d'une
expérience de \chipseq par exemple.

% subsubsection vraisemblance_d_une_s_quence (end)

\subsubsection{Apprentissage du modèle}
\label{ssub:apprentissage_du_mod_le}


Maintenant que nous savons exprimer la vraisemblance d'une séquence régulée par
le motif $\mathcal{M}$, nous pouvons apprendre le meilleur modèle possible
l'ayant générée : c'est la maximisation de la vraisemblance. Soit un ensemble
de séquences $\mathcal{S}$ constitué de $M$ séquences co-régulées
$S[1],\cdots,S[M]$.  Ces séquences étant supposées indépendantes, la
vraisemblance que ces données soient générées par un modèle $\mathcal{M}$ est
le produit sur les séquences de la quantité $P(S[m]|\mathcal{M})$. Il est plus
utile dans ce cas de regarder la log-vraisemblance, s'écrivant alors comme une
somme :

\begin{equation}
    l(\mathcal{S} | \mathcal{M}) = \sum_{m=1}^M \log P(S[m] | \mathcal{M})
\end{equation}

Nous désirons obtenir le modèle $\mathcal{M}$ maximisant cette quantité
\footnote{ La distribution \textit{background} est supposée fixée (par exemple
la chaîne de Markov peut être apprise sur un grand nombre de séquences
intergéniques non codantes).  }.  Cependant, nous ne connaissons pas les
positions exactes des sites, qui sont des \og variables cachées \fg et il
n'existe pas de méthode d'estimation simple permettant de résoudre ce problème.
C'est à ce stade qu'intervient la méthode Espérance-Maximisation
(EM)~\cite{dempster1977maximum}. L'algorithme EM est une méthode itérative qui
part d'un modèle initial $\mathcal{M}^0$, permettant de calculer les poids des
positions dans les séquences (étape E d'espérance), puis estime le meilleur
modèle $\mathcal{M}^1$ étant données ces poids (étape M de maximisation).
L'itération a lieu jusqu'à convergence vers un maximum local. 


Notons $\mathcal{M}^t$ le modèle à l'itération $t$. La probabilité qu'un site
à la position $i$ dans la séquence $S[i]$ soit un site de fixation s'écrit $P(i
| S[m], \mathcal{M}^t)$. On définit la log-vraisemblance moyenne d'un modèle
$\mathcal{M}$ à l'itération $t$ par :

\begin{equation}
    \label{eq:loglikeli-full}
    Q(\mathcal{M}|\mathcal{M}_t,\mathcal{S}) = \sum_m \sum_i P(i | S[m],
    \mathcal{M}^t) \log P(\mathcal{S},i|\mathcal{M})
\end{equation}

Le modèle suivant $\mathcal{M}^{t+1}$ est celui qui maximise cette quantité :

\begin{equation}
    \mathcal{M}^{t+1} = \underset{\mathcal{M}}{\text{argmax}} Q(\mathcal{M}|\mathcal{M}_t,\mathcal{S})
\end{equation}


L'équation \ref{eq:loglikeli-full} se scinde en une partie dépend de
$\mathcal{M}$ et une partie \textit{background} qui n'en dépend pas (eq.
\ref{eq:prob-sequence-oops}), que l'on peut dont ignorer pour ce qui est de la
maximisation. Ainsi, le modèle $\mathcal{M}$ maximise la quantité suivante :

\begin{equation}
    Q(\mathcal{M}|\mathcal{M}_t,\mathcal{S}) = \sum_m \sum_i P(i | S[m],
    \mathcal{M}^t) \log P(S_{i,i+K-1}|\mathcal{M})
\end{equation}

Chaque $K$-mer des séquences de $\mathcal{S}$ est donc pris en compte dans
l'apprentissage en proportion de la croyance courante $P(i | S[m],
\mathcal{M}^t)$ que c'est un site de fixation. 

Pour résumer on a deux étapes:

\begin{itemize}
        

    \item[$\bullet$] étape E : utiliser $\mathcal{M}^t$ pour attribuer un poids à chaque
        $K$-mer des séquences

    \item[$\bullet$] étape M : apprendre $\mathcal{M}^{t+1}$ qui a la plus grande
        vraisemblance de générer les données pondérées par $\mathcal{M}^t$.

\end{itemize}

Reste le problème de choisir un modèle initial adéquat pour ne pas converger
vers un maximum de vraisemblance local. MEME adopte pour cela une approche
semi-exhaustive. Les différents $K$-mers possibles des séquences
d'apprentissage sont successivement utilisés pour générer un modèle initial.
L'algorithme EM est itéré une fois, et le modèle de plus grande probabilité est
finalement gardé come motif initial pour une itération complète.



% subsubsection apprentissage_du_mod_le (end)


% subsection algorithmes_de_type_esp_rance_maximisation (end)

% section recherche_de_motifs_dans_des_crms (end)


\subsection{Incorporation de l'information phylogénétique}
\label{sub:incorporation_de_l_information_phylog_n_tique}



% subsection incorporation_de_l_information_phylog_n_tique (end)
\section{Article} 
\label{sec:article}

\includepdf[pages=-]{articles/imogene-genomebiol.pdf}


% section article (end)




\section{Calcul de la moyenne de la postérieure par une méthode MCMC} 
\label{sec:calcul_de_la_moyenne_de_la_post_rieure_par_une_m_thode_mcmc}

Nous avons voulu savoir si l'approximation réalisée par Imogene lors du calcul
du maximum de l'estimateur de la postérieure modifiée donnait un résultat
effectivement proche du calcul de la moyenne de l'estimateur de la postérieure
non modifiée $\mathcal{P}(w_i|\{\mathcal{A}\})$, où $w_i$ est le vecteur de
poids de la PWM à la position $i$ et $\{\mathcal{A}\}$ est l'ensemble des
alignements de nucléotides observés à cette position dans les sites de
fixation. Néanmoins, l'estimation de la moyenne de cette distribution est
difficile, puisque nous n'avons pas de moyen simple de l'échantillonner. Afin
de contourner ce problème, nous avons eu recours à une méthode de Monte-Carlo
par chaînes de Markov ou MCMC basée sur l'algorithme de
Metropolis-Hastings~\cite{krauth2006statistical}. 


\subsection{Principe de l'algorithme de Metropolis-Hastings}
\label{sub:principe_de_l_algorithme_de_metropolis_hastings}

L'algorithme de Metropolis-Hastings
\cite{metropolis1953equation,hastings1970monte} permet d'échantillonner la
distribution de la distribution postérieure en utilisant le parcours d'une
chaîne de Markov ayant cette distribution pour loi stationnaire. Une tel
processus de Markov est défini par des probabilités de transition $P(w \to w')$
entre deux états $w$ et $w'$. Il converge vers une distribution stationnaire
$\pi(w)$ unique sous deux conditions : (1) les transitions sont réversibles et
le processus satisfait le bilan détaillé $\pi(w)P(w\to w') = \pi(w')P(w'\to
w)$, (2) le processus est ergodique, \cad que tout état est accessible et qu'il
n'y a pas de cycles.  L'algorithme de Metropolis-Hastings repose sur la
construction d'une chaîne de Markov ayant ces propriétés et dont la
distribution d'équilibre $\pi(w)$ est la probabilité que l'on cherche
à échantillonner $P(w)$. Pour cela, on part de l'équation du bilan détaillé,
que l'on peut écrire 

\begin{equation}
    \label{eq:bilan-detaille}
    \frac{P(w \to w')}{P(w' \to w)} = \frac{P(w')}{P(w)}
\end{equation}

La transition $P(w \to w')$ est ensuite décomposée en deux sous-étapes, la
proposition (\textit{proposal}) et l'acceptation (\textit{acceptance}) : 

\begin{equation}
    P(w \to w') = \underbrace{g(w \to w')}_{\text{proposition}} \cdot \underbrace{A(w\to w')}_{\text{acceptation}}
\end{equation}

En insérant dans l'éq. \ref{eq:bilan-detaille} on obtient

\begin{equation}
    \frac{A(w \to w')}{A(w' \to w)} = \frac{P(w')}{g(w \to w')} \frac{g(w' \to w)}{P(w)}
\end{equation}

Plusieurs choix de la fonction d'acceptation sont possibles pour satisfaire
cette équation \cite{hastings1970monte}. Un choix courant, dit choix de
Metropolis,  est :

\begin{equation}
    \label{eq:acceptance}
    A(w \to w') = \min\left(1, \frac{P(w')}{g(w \to w')} \frac{g(w' \to w)}{P(w)}\right)
\end{equation}

Un aspect très pratique de cette quantité est qu'elle est invariante sous
multiplication de la distribution $P(w)$ par un facteur non nul. Autrement dit,
la distribution n'a pas besoin d'être normalisée. Dans un cadre bayésien, cela
veut dire que l'on peut remplacer la postérieure par le produit de la
vraisemblance et du \textit{prior}.\\

La méthode de Metropolis-Hastings se
résume donc ainsi :

\begin{enumerate}
\item Initialiser $w$ à une valeur prise au hasard.
\item Choisir un nouvel état $w'$ tiré selon $g(w \to w')$
\item Accepter l'état avec une probabilité donnée par $A(w \to w')$. Si le nouvel état n'est pas accepté, alors $w'=w$.
\item Itérer jusqu'à convergence
\end{enumerate}

Au final, $w$ étant tiré selon la distribution $P(w)$, sa moyenne est
directement accessible en sommant les poids $w_i(t)$ obtenus au cours des $N$
itérations réalisées :

\begin{equation}
    \langle w \rangle \simeq \frac{1}{N} \sum_{t=1}^N w_i(t)
\end{equation}

Quant au critère de convergence, une possibilité est d'utiliser le Théorème
Centrale Limite (TCL). Celui-ci stipule que la moyenne de $n$ variables
aléatoires indépendantes et identiquement distribuées selon une loi de moyenne
$\mu$ et d'écart-type $\sigma$ de valeurs finies suit, pour $n$ grand, une loi
normale de moyenne $\mu$ et d'écart-type $\sigma/\sqrt{n}$. Dans notre cas, les
échantillons successifs $w_i$ ne sont pas indépendants à cause du fait qu'on
les tire selon la loi $g(w\to w')$. Il faut donc calculer le temps de
décorrélation $T$ pour lequel $\langle w_i(t) w_i(t+T) \rangle \simeq 0$, puis
utiliser les échantillons $w_i(t)$ obtenus toutes les $T$ itérations comme
variables indépendantes.  L'application du TCL permet alors d'arrêter les
itérations lorsqu'une certaine précision désirée est atteinte, par exemple
lorsque $\sigma / \sqrt{n} < 1.96$, critère qui assure que l'on connaît la
vraie valeur moyenne à $95\%$ de confiance.  L'écart-type $\sigma$ étant lui
même estimé à partir des échantillons de l'algorithme, il faut aussi s'assurer
qu'il a convergé. Il est aussi possible, comme nous le verrons par la suite,
d'utiliser une borne inférieure connue à cet écart-type.



% subsection principe_de_l_algorithme_de_metropolis_hastings (end)

\subsection{Application au calcul de la postérieure}
\label{sub:application_au_calcul_de_la_post_rieure}

Dans notre cas, nous souhaitons utiliser l'algorithme de Metropolis-Hastings
pour calculer la valeur moyenne du vecteur de poids $w_i$ en
position $i$ de la PWM selon la distribution postérieure
$\mathcal{P}(w_i|\{\mathcal{A}\})$:

\begin{equation}
    \langle w_i \rangle = \int w_i \mathcal{P}(w_i|\{\mathcal{A}\}) \text{d}w  %\simeq \sum_{t=1}^N w_i(t)
\end{equation}

Il nous faut pour cela définir une loi de proposition $g(w_i \to w_i')$
pertinente. Dans notre cas, les poids $w_i$ doivent rester dans le simplexe de
dimension $3$ défini par $w_A, w_C, w_G >0$ et $w_A+w_C+w_G <1$, le poids $w_T$
étant entièrement déterminé par la normalisation des probabilités
$w_T=1-w_A-w_C-w_G$.  La distribution naturelle possédant cette propriété est
la loi de Dirichlet $\text{Dir}(\al)$, de paramètres
$\al=\{\al_A,\al_C,\al_G,\al_T\}$ et de densité de probabilité

\begin{equation}
    f(w) = \frac{1}{B(\alpha)} \prod_{b\in \{A,C,G,T\}} w_{i,b}^{\al_b - 1}
\end{equation}

où $B(\al)$ est la fonction bêta multinomiale permettant la normalisation.
Cette distribution est la même que celle obtenue dans le cas d'observations
indépendantes (cf article). Afin d'accélérer l'échantillonnage MCMC, nous avons
cherché à régler les paramètres $\al$ de manière à être au plus proche de la
distribution $\mathcal{P}(w_i|\{\mathcal{A}\})$. Dans le cas de $N$ sites
indépendants, celle-ci suit une loi de Dirichlet de paramètres $\al_p + N_i$,
où $\al_p$ est le vecteur de pseudo-counts et $N_i$ le vecteur donnant les
nombres d'observations des nucléotides à la position $i$ au sein des
différentes séquences. Dans le cas réel, le nombre effectif d'observation est
moins grand que le nombre total de séquences du fait du modèle d'évolution.
Nous avons donc défini les paramètres de notre \textit{proposal} comme étant

\begin{equation}
    \al_b = \al_p + N_{\text{eff}}\cdot w_i
\end{equation}

où $N_{\text{eff}}=N_{\text{sites}}\cdot N_{\text{spe}} /2$ avec
$N_{\text{sites}}$ le nombre d'alignements observés et $N_{\text{spe}}$ le
nombre total d'espèces dans l'alignement. Grossièrement, cela revient à dire
que le modèle d'évolution réduit d'un facteur $2$ le nombre de séquences
indépendantes. Nous avons calculé que le taux d'acceptation pour ce paramètre
était de l'ordre de $50\%$, une valeur généralement considérée comme
raisonnable~\cite{krauth2006statistical}. Nous obtenons finalement l'expression
pour la \textit{proposal} :


\begin{equation}
    \label{eq:proposal}
    g(w \to w') = \frac{1}{B(\alpha)} \prod_{b\in \{A,C,G,T\}} (w_{i,b}')^{\al_{p,b} + N_{\text{eff}}\cdot w_{i,b}  - 1}
\end{equation}

Le vecteur $w_i$ est initialisé à la valeur qu'il prendrait si toutes les
séquences orthologues étaient des observations indépendantes  (cf article) :

\begin{equation}
    w_{i,b}(0) = w_{i,b}^\text{inde} = \frac{N_{i,b} + \al_b}{N_{\text{tot}} + \sum_b \al_b}
\end{equation}


Le poids $w_i(1)$ suivant est ensuite tiré selon la probabilité de transition
$g(w_i(0) \to w_i(1))$. Les différentes quantités de l'équation
\ref{eq:acceptance} sont ensuite calculées et la transition est acceptée avec
probabilité $A\left(w_i(0) \to w_i(1)\right)$. 
\\

Reste le problème de la convergence. Nous avons vu dans la section précédente
que l'on pouvait utiliser le théorème centrale limite pour décider de la
convergence. Dans notre cas, nous possédons une borne inférieure de
l'écart-type $\sigma$ de la postérieure :  celui-ci est donné par l'écart-type
$\sigma_{\text{inde}}$ du cas limite où les séquences sont des observations
indépendantes. En effet, dans ce cas limite le nombre d'observations est plus
grand qu'avec un modèle d'évolution, et la déviation standard est donc plus
petite. Notant $\al_{i,b}^\text{inde}=N_{i,b}+\al_b$ et
$\al_0=\sum_b\al_{i,b}^{\text{inde}}$, celle-ci s'écrit

\begin{equation}
    \sigma_{\text{inde}} = \sqrt{\frac{\al_{i,b}^\text{inde}(\al_0-\al_{i,b}^\text{inde}}{\al_0^2(\al_0+1)}} 
\end{equation}

Le TCL peut alors être appliqué en utilisant des échantillons indépendants de
$w_i$ (voir paragraphe suivant
\ref{sub:illustration_de_la_m_thode_mcmc_sur_un_exemple}). Notre critère de
convergence est que l'écart absolu maximum obtenu entre l'estimation de la
moyenne à l'itération courante et les $10$ précédentes estimations doit être
plus petit que $\sigma_{\text{inde}}/\sqrt{n}$, où $n$ est le nombre
d'échantillons indépendants.

% subsection application_au_calcul_de_la_post_rieure (end)


\subsection{Illustration sur un exemple}
\label{sub:illustration_de_la_m_thode_mcmc_sur_un_exemple}

Étudions maintenant un exemple concret. Nous présentons la méthode sur le cas
présenté en fig.~\ref{fig:MCMC/TFBS}, et les résultats ont été obtenus pour le
modèle d'évolution \textit{Felsenstein}. Nous montrons les résultats pour la
position $2$ des sites où les bases $G$ et $C$ sont dégénérées. Le vecteur de
poids $w_i$ est initialisé au cas indépendant $w_i^\text{inde}$. La
distribution de proposition de l'éq.~\ref{eq:proposal}, $g(w_i^\text{inde} \to
w)$, est montrée en fig.~\ref{fig:MCMC/plotDirichlet}. On voit notamment
comment cette distribution de Dirichlet permet de rester dans le simplexe. La
valeur finale de l'estimation de la moyenne de la postérieure est aussi montrée
: elle est relativement proche, indiquant que le choix de la valeur initiale
est effectivement judicieux.
\\

La chaîne MCMC est ensuite lancée. Le taux d'acceptation est calculé comme
valant $62\%$. Les $500$ premiers échantillons $w_i$ sont montrés en figure
\ref{fig:MCMC/plotSampling}. On note dans cette figure que certains points
semblent corrélés : diminutions ou augmentations successives de la valeur
courante $w_i(t)$ sur plusieurs itérations. Pour quantifier cet effet, nous
avons mesuré la corrélation temporelle des échantillons. Celle-ci est estimée
par

\begin{equation}
    C_b(\tau) = \frac{1}{N} \sum_{t=1}^{N-\tau} w_{i,b}(t) w_{i,b}(t+\tau) - \left(\frac{1}{N}\sum_{t=1}^N w_{i,b}(t)\right)^2
\end{equation}

Le logarithme de cette quantité est montrée en figure
\ref{fig:MCMC/plotAutocorr}. L'intérêt du logarithme est de mettre en exergue
le caractère exponentiel de la décorrélation :

\begin{equation}
    C_b(\tau) \propto e^{-\tau/T_b}
\end{equation}

Les temps de décorrelation $T_b \sim 10$ sont estimés en fittant une droite
sur les $20$ premiers points de la courbe. 
\\

Les valeurs des estimateurs de la postérieure obtenues avec la méthode de
descente de gradient (Maximum A Posteriori sur la postérieure modifiée, voir
article) et l'approche MCMC (Moyenne A Posteriori) sont comparées en figure
\ref{fig:MCMC/plotConvergence} en fonction du nombre d'itérations. L'approche
MCMC, bien que convergeant vers un état proche de celui donné par la descente
de gradient, met beaucoup plus de temps à converger : plus de $10,000$
itérations, alors que la descente de gradient n'en requiert que $100$. Au vu de
la faible différence entre les deux résultats, nous avons constamment utilisé
l'approche décrite dans l'article de maximisation de la postérieure modifiée,
ce qui permet un gain de temps considérable pour l'algorithme.

\bfig
\includegraphics[width=0.2\textwidth]{figures/MCMC/TFBS.pdf}
\captionbf{Sites utilisés pour le MCMC}{

    La position étudiée est celle encadrée, contenant au total $10$ G, $8$ C et
    $1$ A.

}
\label{fig:MCMC/TFBS}
\efig

\bfig
\includegraphics[width=0.5\textwidth]{figures/MCMC/plotDirichlet.pdf}
\captionbf{Distribution de la fonction de proposition $g(w_i^\text{inde} \to w)$}{

    La distribution de Dirichlet est réalisée pour $50,000$ tirages aléatoires,
    avec un bin de $0.02$. Les lignes verticales en pointillés indiquent
    l'estimation de la moyenne obtenue après convergence (voir
    fig.~\ref{fig:MCMC/plotConvergence}).

}
\label{fig:MCMC/plotDirichlet}
\efig


\bfig
\includegraphics[width=0.5\textwidth]{figures/MCMC/plotSampling.pdf}
\captionbf{Extrait de l'échantillonnage de $w_i$}{

Les $500$ premiers échantillons $w_i$ de la chaîne MCMC sont montrés.

}
\label{fig:MCMC/plotSampling}
\efig

\bfig
\includegraphics[width=0.5\textwidth]{figures/MCMC/plotAutocorr.pdf}
\captionbf{Fonction d'auto-corrélation de la chaîne MCMC}{

Corrélation entre des échantillons séparés de $t-1$ itérations. Une droite est
fittée sur les $20$ premièrs points, permettant de recueillir
la pente $-T_b$ donnant le temps de décorrélation.

}
\label{fig:MCMC/plotAutocorr}
\efig

\bfig
\includegraphics[width=0.5\textwidth]{figures/MCMC/plotConvergence.pdf}
\captionbf{Comparaison des approches MCMC et par descente de gradient}{

L'approche de maximisation de (l'opposé de) la postérieure par descente de
gradient (rouge) est comparée à l'approche de calcul de la moyenne de la
postérieure par MCMC (noir). Les deux méthodes sont initialisées au même
$w_i^{\text{inde}}$ (ligne pointillée mauve) Alors que la descente de
gradient converge rapidement ($\sim100$ itérations), l'approche MCMC converge
plus lentement, dans ce cas plus de $10,000$ itérations. Au final les deux
approches convergent vers des quantités proches (lignes pointillées rouges et
noires). 

}
\label{fig:MCMC/plotConvergence}
\efig

% subsection illustration_de_la_m_thode_mcmc_sur_un_exemple (end)


% section calcul_de_la_moyenne_de_la_post_rieure_par_une_m_thode_mcmc (end)
